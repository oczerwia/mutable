TODO / Next steps

Debug:
  - size (in datamodel) is completely weird
  - If we set the cardinality, the model state is not adjusted -> I.e. histograms stay the same but the cardinality has changed
  - Look if stored source tables need to be reset on the cardinality storage


today:
[ ] Try implementing sampling (/ perform statistics generation during read in)
[ ] Have one range based estimation completely run and analyzed
[ ] Fully finish data analysis pipeline / generate automated reporting


For later
[ ] Include P-Error (Cardinality Estimation in DBMS: A Comprehensive Benchmark Evaluation)
[ ] Include STATS / STATS-CEB benchmarks (Cardinality Estimation in DBMS: A Comprehensive Benchmark Evaluation)
[ ] Include JOB and remove all LIKE queries


CONFIDENCE BASED LOWE BOUND
Inputs:
- N_R, N_S
- Top-k MCVs: value v_i, freq f_i(R), f_i(S)
- Optional: NDV, fmax, min/max

Algorithm:
1. Initialize LB_join = 0
2. For each MCV v_i:
   a. Choose overlap probability p_i (heuristic, e.g., 0.5)
   b. LB_i = p_i * min(f_i(R), f_i(S))
   c. LB_join += LB_i
3. Optionally adjust for confidence interval (e.g., binomial lower bound)
4. Return LB_join
5. If no MCVs available, fallback:
   LB_join = p * min(fmax_R, fmax_S)


Must solve:
[ ] Make runnable on server -> Server still seems to not work POSTPONED
  [ ] Run full job-light

Naive Range Estimators
[ ] Rule based propagation
[ ] Histogram based propagation


RANGE ESTIMATION IDEAS
[ ] Simplicity done right for Join Ordering gives upper bound
[ ] Could do full independent selectivity as lower bound and dampened selectivity as median / upper bound


small feature:
[ ] Make histogram bin size a system parameter
[ ] Implement sampling for statistics

Refactoring:
  [ ] Understand and clean complete cardinalityStorage
  [ ] Move cardstorage into a cpp file
  [ ] Move cardinality storage retrieval (for join) into estimator
  [ ] Split up functions in CardinalityStorage
    [ ] Matching based on operators first




###############
CODE ASSUMPTIONS
###############

- Selectivity
  - Lots of stuff
- Histograms
  - Even more stuff

###############
CODE Short cuts
###############

- removed some of the job-light lines that were faulty (mostly because of insertion of ',' in the notes section)


#########
INTERVIEW prep
#########


Week 1 (Aug 11–15) – Foundations & Light Start
Daily:

* 30 min LeetCode: Arrays, strings, hash maps
* 15 min NebulaStream reading
* 15 min STAR stories
  End of Week: 3 STAR stories ready, 2–3 NebulaStream questions

Week 2 (Aug 18–22) – Thesis Presentation Draft #1
Daily:

* 30 min LeetCode: Sliding window, sorting
* 20 min DB fundamentals: Joins, indexing, execution strategies
* 20 min Thesis slides: Outline, motivation, approach, current results
  End of Week: Rough slide deck, 5-min thesis explanation without slides

Week 3 (Aug 25–29) – Database Deep Dive
Daily:

* 30 min LeetCode: BFS/DFS, simple graphs
* 30 min DB review: Transactions, ACID, isolation, cost models, cardinality estimation pitfalls
* 10 min thesis elevator pitch
  End of Week: DB review cheat sheet, polished resilience STAR story

Week 4 (Sep 1–5) – Technical Integration
Daily:

* 30 min LeetCode: Mixed topics
* 30 min Map DB concepts to thesis
* 20 min Polish slides with baseline plots
  End of Week: Presentation draft #2, rehearsed 15–20 min run-through

Week 5 (Sep 8–12) – Mock Interview Rounds
Daily:

* 20 min LeetCode: Timed problems
* 30 min Mock behavioral or DB questions (alternate days)
* 20 min Presentation timing & Q\&A
  End of Week: 1 full mock interview, fix identified gaps

Week 6 (Sep 15–19) – Final Polish
Daily:

* 20 min LeetCode: Review common patterns
* 20 min Presentation final polish
* 20 min Q\&A practice
  End of Week: Final deck + backup slides, STAR stories memorized

Interview Week (Sep 22–26)

* Light LeetCode warmups (1 problem/day)
* Review NebulaStream notes + questions
* 1–2 full timed presentation rehearsals
* Good sleep, light workouts, low stress